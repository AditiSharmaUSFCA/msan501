{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading files\n",
    "\n",
    "The goal of this lecture-lab is to learn how to extract data from files on your laptop's disk. We'll load words from a text file and numbers from data files.  Along the way, we'll learn more about filenames and paths to files. The first two elements of our generic analytics program template says to acquire data and then load it into a data structure:\n",
    "\n",
    "1. Acquire data, which means finding a suitable file or collecting data from the web and storing in a file\n",
    "2. Load data from disk and place into memory organized into data structures\n",
    "\n",
    "For now, we'll satisfy the first step by just downloading ready-made data files from the web by hand. In [MSAN692 -- Data Acquisition](https://github.com/parrt/msan692), we'll learn all about how to pull data from the web programmatically. This lecture focuses on the second step in the analytics program template.\n",
    "\n",
    "As we go along, I'm going to repeatedly ask you to type in a bunch of these examples. It's critical that you learn the code patterns associated with loading data from files. Please type in your code without cutting and pasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are files?\n",
    "\n",
    "As we've discussed before, both the disk and RAM are forms of memory. RAM is much faster (but smaller) than the disk but RAM all disappears when the power goes out. Disks, on the other hand, are persistent. A file is simply a chunk of data on the disk identified by a filename. You use files all the time. For example, we can double-click on a text file or Excel file, which opens an application to display those files. \n",
    "\n",
    "We need to be able to write Python programs that read data from files just like, say, Excel does.  Accessing data in RAM is very easy in a Python program, we simply refer to the various elements in a list using an index, such as `names[i]`.  File data is less convenient to access  because we have to explicitly load the file into working memory first.  For example, we might want to load a list of names from a file into a `names` list. \n",
    "\n",
    "If a file is too big to fit into memory all at once, we have to process the data in chunks.  For now, let's assume all files fit in memory. \n",
    "\n",
    "Even so, accessing files is a bit of a hassle because we must explicitly tell Python to open a file and then close it when we're done. We also must distinguish between reading and writing from/to a file, which dictates the mood in which we open the file.  We can open the file in read, write, or append mode. For this lab, we will only concern ourselves with the default case of \"opening a file for reading.\" Here is how to open a file called `foo.txt` in read mode (the default) then immediately close that file:\n",
    "\n",
    "```\n",
    "f = open('foo.txt')  # open for read mode\n",
    "f.close()            # ok, we're done\n",
    "```\n",
    "\n",
    "Hmm...what kind of object is returned from `open()` and stored in `f`? Why do we have to close files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File descriptors\n",
    "\n",
    "When we open a file, Python gives us a \"file object\" that is really just a handle or cookie that the operating system gives us. It's a unique identifier and how the operating system likes to identify a file that we work with. The file object is not the filename and is also not the file itself on the disk. It's really just a descriptor and a reference to the file.\n",
    "\n",
    "We will use a filename to get a file object using `open()` and use the file object to get the file contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'file'>\n",
      "<open file 'data/prices.txt', mode 'r' at 0x106c429c0>\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/prices.txt\")\n",
    "print type(f)\n",
    "print f\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The close operation informs the operating system that you no longer need that resource. The operating system can only open so many files at once so you should close files when you're done using them. \n",
    "\n",
    "Later, when you are learning to write data to files, the close operation is also important. Closing a file flushes any data in memory buffers that needs to be written. From the Python documentation:\n",
    "\n",
    "> \"It is a common bug to write a program where you have the code to add all the data you want to a file, but the program does not end up creating a file. Usually this means you forgot to close the file.\"\n",
    "\n",
    "<img src=\"images/redbang.png\" width=30 align=\"left\"> To help avoid confusion, keep this analogy in mind. Your house (file) contents is different than your address (file name) and different than a piece of paper with the address written on it (file descriptor). More specifically:\n",
    "\n",
    "1. The filename is a string that identifies a file on the disk. It can be fully qualified or relative to the current working directory.\n",
    "\n",
    "2. The file object is not the filename and is also not the file itself on the disk. It's really just a descriptor and a reference to the file.\n",
    "\n",
    "3. The contents of the file is different than the filename and the file (descriptor) object that Python gives us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File names and paths\n",
    "\n",
    "You know what a file name is because you've created lots of files before. (BTW, another reminder not to use spaces in your file or directory names.) *Paths* are what we call fully qualified filenames because they give a description of the directories from the root of the file system. The root of the file system is identified with `/` forward slashat the start of a pathname. You are probably used to seeing it as \"Macintosh HD\" but from a programming point of view, it's just `/`. Here's a useful diagram showing the components of a fully qualified pathname to a file called `view.py`:\n",
    "\n",
    "<img src=images/path-names.png width=750>\n",
    "\n",
    "As a shorthand, you can start a path with `~`, which means \"my home directory\". On a Mac that's `/Users/parrt` or whatever your user ID is. On Linux, it's probably `/home/parrt`.\n",
    "\n",
    "The last element in a path is either a filename or a directory. For example to refer to the directory holding `view.py` in the above diagram, use path `/Users/parrt/classes/msan501/images-parrt`. Or, using the shortcut, the fully qualified path is `~/classes/msan501/images-parrt`. Here's an example bash session that uses some fully qualified paths:\n",
    "\n",
    "```bash\n",
    "$ ls /Users/parrt/classes/msan501/images-parrt/view.py\n",
    "/Users/parrt/classes/msan501/images-parrt/view.py\n",
    "$ cd /Users/parrt/classes/msan501/images-parrtâ€¨",
    "$ pwd\n",
    "/Users/parrt/classes/msan501/images-parrt\n",
    "$ cd ~/classes/msan501/images-parrt\n",
    "$ pwd\n",
    "/Users/parrt/classes/msan501/images-parrt\n",
    "```\n",
    "\n",
    "### Current working directory\n",
    "\n",
    "All programs run with the notion of a *current working directory*. So, if a program is running inside the directory `~/classes/msan501/images-parrt`, then the program could refer to any data files sitting in that directory with just a file name--no path is required.  For example, let's use the `ls` program to demonstrate the different kinds of paths.\n",
    "\n",
    "```bash\n",
    "$ cd ~/classes/msan501/images-parrt\n",
    "$ ls\n",
    "view.py\n",
    "$ ls /Users/parrt/classes/msan501\n",
    "images-parrt/\n",
    "$ ls /Users/parrt/classes\n",
    "msan501/\n",
    "```\n",
    "\n",
    "Any path that does not start with `~` or `/` is called a *relative pathname*. For completeness, note that `..` means the directory above the current working directory:\n",
    "\n",
    "```bash\n",
    "$ cd ~/classes/msan501/images-parrt\n",
    "$ ls ..\n",
    "images-parrt/\n",
    "$ ls ../..\n",
    "msan501/\n",
    "```\n",
    "\n",
    "Sometimes you will see me use `/tmp`, which is a temporary directory or dumping ground.  All files in that directory are usually erased when you reboot.\n",
    "\n",
    "## Loading text files\n",
    "\n",
    "As we discussed early in the semester, files are just bits. It's how we interpret the bits that is meaningful. The bits could represent an image, a movie, an article, data, Python program text, whatever. Let's call any file containing characters a *text file* and anything else a *binary file*.\n",
    "\n",
    "Text files are usually 1 byte per character (8 bits) and have the notion of a line. A line is just a sequence of characters terminated with either `\\r\\n` (Windows) or `\\n` (UNIX, Mac). A text file is usually then a sequence of lines. Download this sample text file, [IntroIstanbul.txt](https://raw.githubusercontent.com/parrt/msan501/master/notes/data/IntroIstanbul.txt) so we have something to work with. You can save it in `/tmp` or whatever directory you are using for in class work. For the purposes of this discussion, I have data files in a subdirectory called `data` of this notes directory.\n",
    "\n",
    "The first 10 lines of the file look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  \r\n",
      "  \r\n",
      "    \r\n",
      "      \r\n",
      "        The City and ITS People\r\n",
      "        Istanbul is one of the worlds most venerable cities. Part\r\n",
      "        of the citys allure is its setting, where Europe faces Asia acrÂ­oss\r\n",
      "        the winding turquoise waters of the Bosphorus, making it the only city\r\n",
      "        in the world to bridge two continents.\r\n"
     ]
    }
   ],
   "source": [
    "! head -10 data/IntroIstanbul.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore the \"`!`\" on the front as it is just telling this Jupyter notebook to run the terminal command that follows. If you want you can think of `!` as the `$` terminal prompt in this context.\n",
    "\n",
    "Now, let's examine the contents of the file in a raw fashion rather than with a text editor. The `od` command (octal dump) is useful for looking at the bytes of the file. Use option `-c` to see the contents as 1-byte characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000   \\n          \\n          \\n                  \\n                \r\n",
      "0000020           \\n                                   T   h   e       C\r\n",
      "0000040    i   t   y       a   n   d       I   T   S       P   e   o   p\r\n",
      "0000060    l   e  \\n                                   I   s   t   a   n\r\n",
      "0000100    b   u   l       i   s       o   n   e       o   f       t   h\r\n"
     ]
    }
   ],
   "source": [
    "! od -c data/IntroIstanbul.txt | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That \"`| head -5`\" *pipes* (the vertical bar \"`|`\" looks like a pipe) the output of the `od` command to the `head` program, which gives this the first five lines of the output. When we have a lot of output we can also pipe the output to the `more` program to paginate long output.\n",
    "\n",
    "```bash\n",
    "$ od -c data/IntroIstanbul.txt | more\n",
    "...\n",
    "```\n",
    "\n",
    "The `\\n` character you see represents the single character we know as the carriage return. The numbers on the left are the character offsets into the file (it looks like they are octal not decimal, btw; use `-A d` to get decimal addresses).\n",
    "\n",
    "Let's look at some common programming patterns dealing with text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Load all file contents into a string.\n",
    "\n",
    "The sequence of operation is open, load, close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \n",
      "  \n",
      "    \n",
      "      \n",
      "        The City and ITS People\n",
      "        Istanbul is one of the worlds most venerable cities. Part\n",
      "        of the citys allure is its setting, where Europe faces Asia acrÂ­oss\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "f = open('data/IntroIstanbul.txt')\n",
    "contents = f.read() # read all content of the file\n",
    "f.close()\n",
    "print contents[0:200] # print just the first 200 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "*Without cutting and pasting*, type in that sequence and make sure you can print the contents of the file from Python. Instead of `data`, use whatever directory you saved that IntroIstanbul.txt in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Load all words of file into a list.\n",
    "\n",
    "This pattern is just an extension of the previous where we `split()` on the space character to get a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '', '\\n', '', '\\n', '', '', '', '\\n', '', '', '', '', '', '\\n', '', '', '', '', '', '', '', 'The', 'City', 'and', 'ITS', 'People\\n', '', '', '', '', '', '', '', 'Istanbul', 'is', 'one', 'of', 'the', 'worlds', 'most', 'venerable', 'cities.', 'Part\\n', '', '', '', '', '', '', '', 'of', 'the', 'citys', 'allure', 'is', 'its', 'setting,', 'where', 'Europe', 'faces', 'Asia', 'acr\\xc2\\xadoss\\n', '', '', '', '', '', '', '', 'the', 'winding', 'turquoise', 'waters', 'of', 'the', 'Bosphorus,', 'making', 'it', 'the', 'only', 'city\\n', '', '', '', '', '', '', '', 'in', 'the', 'world', 'to', 'bridge', 'two', 'continents.\\n', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "f = open('data/IntroIstanbul.txt')\n",
    "contents = f.read() # read all content of the file\n",
    "f.close()\n",
    "words = contents.split(' ')\n",
    "print words[0:100] # print first 100 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are splitting on the space character, newlines and multiple space characters in a row yield \"words\" that are not useful. We need to transform that list into a new list before it is useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Using the *filter* programming pattern filters `words` for only those words greater than 1 character; place into another list called `words2`. Hint `len(s)` gets the length of string `s`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all lines of a file\n",
    "\n",
    "Reading the contents of a file into a string is not always that useful. We typically want to deal with the words, as we just saw, or the lines of a text file.  Natural language processing (NLP) would focus on using the words, but let's look at some data files, which typically structure files as lines of data.  Each line represents an observation, data point, or record. \n",
    "\n",
    "We could split the text contents by `\\n` to get the lines, but it is so common that Python provides functions to do that for us. To give us some data to play with, download [prices.txt](https://raw.githubusercontent.com/parrt/msan501/master/notes/data/prices.txt) that has a list of prices, one price per line. Here's another very common programming pattern:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Read all of the lines of the file into a list.\n",
    "\n",
    "The sequence is open, read lines, close:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.605\\n', '0.600\\n', '0.594\\n', '0.592\\n', '0.600\\n', '0.616\\n', '0.623\\n', '0.628\\n', '0.630\\n', '0.629\\n']\n"
     ]
    }
   ],
   "source": [
    "f = open('data/prices.txt')\n",
    "prices = f.readlines() # get lines of file into a list\n",
    "f.close()\n",
    "print prices[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "*Without cutting and pasting*, type in that code and make sure you can read the lines of the file into a list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting list of strings to numpy array\n",
    "\n",
    "The numbers have the `\\n` character on the end but that's not a problem because we can easily convert that using [NumPy](http://www.numpy.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.605,  0.6  ,  0.594,  0.592,  0.6  ,  0.616,  0.623,  0.628,\n",
       "        0.63 ,  0.629])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "prices = np.array(prices, dtype='float') # convert to array of numbers\n",
    "prices[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Add this conversion to the previous exercise and make sure you get an `array` as output.  (I'm trying to give you repeated experience typing code that reads data from a file and processes it in some way.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern:  load list of numbers into a numpy array\n",
    "\n",
    "If we combine these code snippets, the pattern is loading a list of numbers into a numpy `array`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CSV files\n",
    "\n",
    "Let's look at a more complicated data file. Download [heights.csv](https://raw.githubusercontent.com/parrt/msan501/master/notes/data/player-heights.csv), which starts out like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football height, Basketball height\r\n",
      "6.329999924, 6.079999924\r\n",
      "6.5, 6.579999924\r\n",
      "6.5, 6.25\r\n"
     ]
    }
   ],
   "source": [
    "! head -4 data/player-heights.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still a text file, but now we start to get the idea that text files can follow a particular format. In this case, we recognize it as a *comma-separated value* (CSV) file. It also has a header line that names the columns, which means we need to treat the first line differently than the remainder of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Load a CSV file into a 2D numpy array.\n",
    "\n",
    "We already know how to open a file and get the lines, so let's do that and also separate the lines into the header and the data components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football height, Basketball height\n",
      "6.329999924, 6.079999924\n",
      "6.5, 6.579999924\n",
      "6.5, 6.25\n",
      "6.25, 6.579999924\n",
      "6.5, 6.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f = open('data/player-heights.csv')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "header = lines[0]\n",
    "data = lines[1:]\n",
    "print header,   # A trailing comma indicates no newline at end\n",
    "for d in data[0:5]:\n",
    "    print d,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Type in that code and make sure you get the header and the first five lines of data printed out.\n",
    "\n",
    "Each row of the data is a string with two numbers in it. We need to convert that string into a list with two floating-point numbers using `split(',')`.  Combining all of those two-element lists into an overall list gives us the two-dimensional table we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Convert the `data` list of strings to a new list of lists called `data2` like this:\n",
    "\n",
    "```python\n",
    "[['6.329999924', ' 6.079999924\\n'], ['6.5', ' 6.579999924\\n'], ['6.5', ' 6.25\\n']]\n",
    "```\n",
    "\n",
    "Use a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['6.329999924', ' 6.079999924\\n'], ['6.5', ' 6.579999924\\n'], ['6.5', ' 6.25\\n']]\n"
     ]
    }
   ],
   "source": [
    "data2 = [line.split(',') for line in data]\n",
    "print data2[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert heights to numpy array\n",
    "\n",
    "Now we are ready to convert that data to a two-dimensional array full of numbers not strings. The numpy `array()` helps us do the conversion from individual strings to numbers and also understands that a list of lists is a two dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.32999992  6.07999992]\n",
      " [ 6.5         6.57999992]\n",
      " [ 6.5         6.25      ]\n",
      " [ 6.25        6.57999992]\n",
      " [ 6.5         6.25      ]]\n"
     ]
    }
   ],
   "source": [
    "data2 = np.array(data2, dtype='float')\n",
    "print data2[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas to load CSV files\n",
    "\n",
    "Of course, loading CSV is something that data scientists need to do all of the time and so there is a simple function you can use in the future from [Pandas](http://pandas.pydata.org),  another library you will probably become very familiar with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  0.605\n",
       "1  0.600\n",
       "2  0.594\n",
       "3  0.592\n",
       "4  0.600\n",
       "5  0.616\n",
       "6  0.623\n",
       "7  0.628\n",
       "8  0.630\n",
       "9  0.629"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "prices = pandas.read_csv('data/prices.txt', header=None)\n",
    "prices[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(`header=None` indicates that there are no column names in the first line of the file.)\n",
    "\n",
    "This even works for CSV files with header rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Football height</th>\n",
       "      <th>Basketball height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.33</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.50</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.50</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.25</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.50</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.33</td>\n",
       "      <td>5.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.25</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.17</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.42</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.33</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Football height   Basketball height\n",
       "0             6.33                6.08\n",
       "1             6.50                6.58\n",
       "2             6.50                6.25\n",
       "3             6.25                6.58\n",
       "4             6.50                6.25\n",
       "5             6.33                5.92\n",
       "6             6.25                7.00\n",
       "7             6.17                6.41\n",
       "8             6.42                6.75\n",
       "9             6.33                6.25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('data/player-heights.csv')\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see this stuff again in [Manipulating and Visualizing Data](data.md).\n",
    "\n",
    "## Processing files line by line\n",
    "\n",
    "The previous mechanism for getting lines of text into memory works well except that it requires we load everything into memory all at once. That is pretty inefficient and limits the size of the data we can process to the amount of memory we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Read data line by line not all at once.\n",
    "\n",
    "We can use a for-each loop where the sequence of data is the file descriptor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605\n",
      "0.6\n",
      "0.594\n",
      "0.592\n",
      "0.6\n",
      "0.616\n",
      "0.623\n",
      "0.628\n",
      "0.63\n",
      "0.629\n",
      "0.629\n",
      "0.626\n",
      "0.627\n",
      "0.637\n",
      "0.643\n",
      "0.651\n",
      "0.659\n",
      "0.665\n",
      "0.667\n",
      "0.667\n",
      "0.666\n",
      "0.665\n",
      "0.664\n",
      "0.665\n",
      "0.648\n",
      "0.647\n",
      "0.647\n",
      "0.649\n",
      "0.655\n",
      "0.663\n",
      "0.674\n",
      "0.682\n",
      "0.688\n",
      "0.69\n",
      "0.695\n",
      "0.705\n",
      "0.716\n",
      "0.73\n",
      "0.755\n",
      "0.802\n",
      "0.844\n",
      "0.901\n",
      "0.949\n",
      "0.988\n",
      "1.02\n",
      "1.028\n",
      "1.041\n",
      "1.065\n",
      "1.131\n",
      "1.207\n",
      "1.252\n",
      "1.264\n",
      "1.266\n",
      "1.269\n",
      "1.271\n",
      "1.267\n",
      "1.257\n",
      "1.25\n",
      "1.25\n",
      "1.258\n",
      "1.298\n",
      "1.382\n",
      "1.417\n",
      "1.412\n",
      "1.4\n",
      "1.391\n",
      "1.382\n",
      "1.376\n",
      "1.376\n",
      "1.371\n",
      "1.369\n",
      "1.365\n",
      "1.358\n",
      "1.334\n",
      "1.284\n",
      "1.225\n",
      "1.237\n",
      "1.309\n",
      "1.331\n",
      "1.323\n",
      "1.307\n",
      "1.295\n",
      "1.283\n",
      "1.26\n",
      "1.23\n",
      "1.187\n",
      "1.152\n",
      "1.215\n",
      "1.259\n",
      "1.277\n",
      "1.288\n",
      "1.285\n",
      "1.274\n",
      "1.255\n",
      "1.241\n",
      "1.231\n",
      "1.216\n",
      "1.209\n",
      "1.21\n",
      "1.227\n",
      "1.236\n",
      "1.229\n",
      "1.212\n",
      "1.196\n",
      "1.203\n",
      "1.209\n",
      "1.207\n",
      "1.193\n",
      "1.148\n",
      "1.131\n",
      "1.159\n",
      "1.205\n",
      "1.231\n",
      "1.241\n",
      "1.242\n",
      "1.229\n",
      "1.216\n",
      "1.204\n",
      "1.207\n",
      "1.208\n",
      "1.194\n",
      "1.12\n",
      "0.981\n",
      "0.888\n",
      "0.923\n",
      "0.955\n",
      "0.89\n",
      "0.843\n",
      "0.86\n",
      "0.831\n",
      "0.821\n",
      "0.823\n",
      "0.862\n",
      "0.905\n",
      "0.912\n",
      "0.934\n",
      "0.941\n",
      "0.958\n",
      "0.971\n",
      "0.995\n",
      "0.99\n",
      "0.976\n",
      "0.976\n",
      "0.961\n",
      "0.933\n",
      "0.913\n",
      "0.904\n",
      "0.93\n",
      "0.955\n",
      "0.955\n",
      "0.967\n",
      "0.987\n",
      "0.974\n",
      "0.957\n",
      "0.949\n",
      "0.93\n",
      "0.918\n",
      "0.926\n",
      "0.94\n",
      "1.065\n",
      "1.119\n",
      "1.114\n",
      "1.092\n",
      "1.057\n",
      "1.029\n",
      "1.027\n",
      "0.999\n",
      "0.98\n",
      "1.042\n",
      "1.037\n",
      "1.023\n",
      "1.044\n",
      "1.061\n",
      "1.088\n",
      "1.084\n",
      "1.19\n",
      "1.294\n",
      "1.378\n",
      "1.377\n",
      "1.354\n",
      "1.247\n",
      "1.143\n",
      "1.082\n",
      "1.104\n",
      "1.156\n",
      "1.16\n",
      "1.127\n",
      "1.14\n",
      "1.143\n",
      "1.122\n",
      "1.134\n",
      "1.123\n",
      "1.073\n",
      "1.054\n",
      "1.058\n",
      "1.079\n",
      "1.136\n",
      "1.179\n",
      "1.174\n",
      "1.158\n",
      "1.158\n",
      "1.154\n",
      "1.159\n",
      "1.136\n",
      "1.117\n",
      "1.108\n",
      "1.098\n",
      "1.112\n",
      "1.129\n",
      "1.13\n",
      "1.109\n",
      "1.097\n",
      "1.085\n",
      "1.127\n",
      "1.113\n",
      "1.07\n",
      "1.043\n",
      "1.051\n",
      "1.045\n",
      "1.064\n",
      "1.08\n",
      "1.106\n",
      "1.136\n",
      "1.182\n",
      "1.177\n",
      "1.152\n",
      "1.163\n",
      "1.143\n",
      "1.129\n",
      "1.12\n",
      "1.115\n",
      "1.14\n",
      "1.2\n",
      "1.226\n",
      "1.195\n",
      "1.164\n",
      "1.148\n",
      "1.127\n",
      "1.101\n",
      "1.101\n",
      "1.129\n",
      "1.124\n",
      "1.162\n",
      "1.251\n",
      "1.323\n",
      "1.299\n",
      "1.272\n",
      "1.24\n",
      "1.234\n",
      "1.227\n",
      "1.25\n",
      "1.26\n",
      "1.261\n",
      "1.255\n",
      "1.235\n",
      "1.231\n",
      "1.226\n",
      "1.229\n",
      "1.205\n",
      "1.253\n",
      "1.277\n",
      "1.242\n",
      "1.213\n",
      "1.177\n",
      "1.131\n",
      "1.082\n",
      "1.041\n",
      "1.052\n",
      "1.092\n",
      "1.094\n",
      "1.079\n",
      "1.052\n",
      "1.033\n",
      "1.042\n",
      "1.028\n",
      "0.986\n",
      "0.972\n",
      "0.955\n",
      "0.991\n",
      "1.177\n",
      "1.178\n",
      "1.148\n",
      "1.189\n",
      "1.255\n",
      "1.28\n",
      "1.274\n",
      "1.264\n",
      "1.298\n",
      "1.301\n",
      "1.369\n",
      "1.541\n",
      "1.506\n",
      "1.498\n",
      "1.617\n",
      "1.593\n",
      "1.51\n",
      "1.582\n",
      "1.559\n",
      "1.555\n",
      "1.489\n",
      "1.472\n",
      "1.484\n",
      "1.447\n",
      "1.564\n",
      "1.729\n",
      "1.64\n",
      "1.482\n",
      "1.427\n",
      "1.531\n",
      "1.362\n",
      "1.263\n",
      "1.131\n",
      "1.139\n",
      "1.13\n",
      "1.241\n",
      "1.407\n",
      "1.421\n",
      "1.404\n",
      "1.412\n",
      "1.423\n",
      "1.422\n",
      "1.449\n",
      "1.448\n",
      "1.394\n",
      "1.473\n",
      "1.641\n",
      "1.748\n",
      "1.659\n",
      "1.542\n",
      "1.514\n",
      "1.524\n",
      "1.628\n",
      "1.728\n",
      "1.603\n",
      "1.535\n",
      "1.494\n",
      "1.592\n",
      "1.672\n",
      "1.766\n",
      "1.833\n",
      "2.009\n",
      "2.041\n",
      "1.939\n",
      "1.898\n",
      "1.891\n"
     ]
    }
   ],
   "source": [
    "f = open('data/prices.txt')\n",
    "for line in f: # for each line in the file\n",
    "    print float(line) # process the line in some way\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Type in this new version of processing the lines of the file. No cutting and pasting!\n",
    "\n",
    "Keep in mind that once you close the file, you cannot read anymore data from it:\n",
    "\n",
    "\n",
    "```python\n",
    "f = open('/tmp/prices.txt')\n",
    "f.close()\n",
    "f.read()\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "ValueError: I/O operation on closed file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The key programming patterns to take away from this lecture are:\n",
    "\n",
    "* **Pattern**: Load all file contents into a string.\n",
    "* **Pattern**: Load all words of file into a list.\n",
    "* **Pattern**: Read all of the lines of the file into a list.\n",
    "* **Pattern**: Load list of numbers into a numpy array.\n",
    "* **Pattern**: Load a CSV file into a 2D numpy array.\n",
    "\n",
    "You should be able to code those patterns quickly and easily, and without cutting and pasting from stackoverflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "484px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
